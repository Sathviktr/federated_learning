{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: 647 samples saved.\n",
      "Client 1: 647 samples saved.\n",
      "Client 2: 647 samples saved.\n",
      "Client 3: 506 samples saved.\n",
      "Data preprocessing complete for 4 clients and test set!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../data/stock_data/TSLA.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "# Scale the closing price\n",
    "close_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[\"Close_Scaled\"] = close_scaler.fit_transform(df[[\"Close\"]])\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split into 4 client datasets with overlap\n",
    "total_len = len(df)\n",
    "client_size = int(total_len / (4 * 0.8))  # ~944 points per client\n",
    "overlap = int(client_size * 0.2)\n",
    "clients_data = []\n",
    "for client_id in range(4):\n",
    "    start = client_id * (client_size - overlap)\n",
    "    if start < 0:\n",
    "        start = 0\n",
    "    end = min(start + client_size, total_len)\n",
    "    client_df = df.iloc[start:end]\n",
    "    X, y = [], []\n",
    "    lookback = 60\n",
    "    client_data = client_df['Close_Scaled'].values\n",
    "    for i in range(lookback, len(client_data)):\n",
    "        X.append(client_data[i-lookback:i])\n",
    "        y.append(client_data[i])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    clients_data.append((X, y))\n",
    "    joblib.dump(X, f\"../processed_data/X_client_{client_id}.pkl\")\n",
    "    joblib.dump(y, f\"../processed_data/y_client_{client_id}.pkl\")\n",
    "    print(f\"Client {client_id}: {len(y)} samples saved.\")\n",
    "\n",
    "# Save test data (last 20%)\n",
    "train_size = int(total_len * 0.8)\n",
    "test_data = df['Close_Scaled'].values[train_size:]\n",
    "X_test, y_test = [], []\n",
    "for i in range(lookback, len(test_data)):\n",
    "    X_test.append(test_data[i-lookback:i])\n",
    "    y_test.append(test_data[i])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "joblib.dump(X_test, \"../processed_data/X_test_seq.pkl\")\n",
    "joblib.dump(y_test, \"../processed_data/y_test_seq.pkl\")\n",
    "joblib.dump(close_scaler, '../processed_data/close_scaler.pkl')\n",
    "\n",
    "print(\"Data preprocessing complete for 4 clients and test set!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
